---
title: "[논문리뷰] ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)"
last_modified_at: 2025-02-10
categories:
  - 논문리뷰
  - 딥러닝
  - 컴퓨터비전

tags:
  - Computer Vision
  - AI
  - Image Classification
  - AlexNet Model

excerpt: "AlexNet 논문 리뷰"
use_math: true
classes: wide
math_engine: katex
---

> NeurIPS 2012. [[논문 링크](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)]  
> 저자: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton (University of Toronto)  
> 출판일: 2012년

## 소개

AlexNet은 딥러닝이 컴퓨터 비전 분야에서 본격적으로 활용되기 시작한 계기가 된 모델로, 2012년 ImageNet Large Scale Visual Recognition Challenge (ILSVRC)에서 압도적인 성능을 기록하며 CNN 기반 이미지 분류 모델의 가능성을 입증하였다.

![AlexNet 구조](/assets/img/alexnet/alexnet-architecture.webp)

AlexNet의 주요 기여는 다음과 같다:
1. **ReLU 활성화 함수 도입**: Sigmoid나 Tanh보다 빠른 학습을 가능하게 함.
2. **GPU 활용**: 딥러닝 학습을 가속화하여 더 깊은 모델을 훈련할 수 있도록 함.
3. **Dropout 사용**: 과적합을 방지하는 기법 도입.
4. **Overlapping Pooling**: 더 나은 특징 추출을 위한 개선된 풀링 기법.
5. **Data Augmentation**: 훈련 데이터 확장을 통해 일반화 성능 향상.

## AlexNet 구조

AlexNet은 LeNet의 개념을 확장하여 더 깊고 넓은 네트워크를 설계하였다. 주요 네트워크 구성 요소는 다음과 같다:

![AlexNet 레이어 구성](/assets/img/alexnet/alexnet-layers.webp)

### 1. 입력 레이어
ImageNet 데이터셋의 \( 224 \times 224 \) RGB 이미지를 입력으로 사용한다.

### 2. Convolution Layer 1
첫 번째 합성곱 계층에서는 **11 × 11 커널, 96개 필터, Stride 4**를 사용하여 특징 맵을 생성한다.

$$
C1: 224 \times 224 \to 55 \times 55 \text{ (96 feature maps)}
$$

### 3. Max Pooling 1
풀링 연산을 통해 크기를 줄이고, 불필요한 정보를 제거한다.

$$
S2: 55 \times 55 \to 27 \times 27
$$

### 4. Convolution Layer 2
**5 × 5 커널, 256개 필터**를 사용한 두 번째 합성곱 계층.

$$
C3: 27 \times 27 \to 13 \times 13 \text{ (256 feature maps)}
$$

### 5. Max Pooling 2
두 번째 풀링 계층에서 크기를 줄인다.

$$
S4: 13 \times 13 \to 6 \times 6
$$

### 6. Fully Connected Layers
- **F5**: 4096개의 뉴런을 가지는 Fully Connected Layer.
- **F6**: 또 다른 4096개의 뉴런을 가지는 Fully Connected Layer.
- **Output Layer**: Softmax 활성화 함수를 사용하여 1000개의 클래스 예측.

## AlexNet의 학습 방법

- **Stochastic Gradient Descent (SGD) 적용**
- **Momentum 사용 (0.9)**
- **Weight Decay 적용 (0.0005)**
- **Batch Size: 128**
- **Dropout Regularization (0.5)**

## 실험 및 결과

AlexNet은 ILSVRC 2012에서 **16.4% Top-5 Error Rate**를 기록하며, 기존 최고 성능 모델(VGGNet 이전)의 26% 대비 큰 성능 향상을 이루었다.

![AlexNet 성능 비교](/assets/img/alexnet/alexnet-performance.webp)

주요 성과는 다음과 같다:
- **기존 모델 대비 획기적인 성능 향상**
- **ReLU 활성화 함수를 사용한 빠른 학습**
- **GPU 병렬 연산을 활용하여 깊은 네트워크 학습 가능**

## 결론

AlexNet은 CNN이 컴퓨터 비전에서 중요한 역할을 하게 된 계기가 된 모델로, 이후 등장한 VGGNet, ResNet, EfficientNet 등의 발전에 큰 영향을 미쳤다.

1. **딥러닝을 본격적으로 컴퓨터 비전에 도입**
2. **ReLU, Dropout, Data Augmentation 등의 기법을 도입하여 성능 향상**
3. **GPU를 활용한 딥러닝 모델 학습 가속화**

현재에도 AlexNet은 CNN 구조를 학습하는 기본적인 모델로 많이 사용되며, 이미지 분류 및 다양한 딥러닝 연구의 기초가 되고 있다.