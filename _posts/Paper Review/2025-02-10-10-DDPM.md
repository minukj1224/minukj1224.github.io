---
title: "[논문리뷰] Denoising Diffusion Probabilistic Models (DDPM)"
last_modified_at: 2025-02-10
categories:
  - 논문리뷰
tags:
  - Computer Vision
  - AI
  - Image Generation
  - Diffusion Model

excerpt: "DDPM 논문 리뷰"
use_math: true
classes: wide
math_engine: katex
---

> NeurIPS 2020. [[논문 링크](https://arxiv.org/abs/2006.11239)] [[Github](https://github.com/lucidrains/denoising-diffusion-pytorch)]  
> 저자: Jonathan Ho, Ajay Jain, Pieter Abbeel (UC Berkeley)  
> 출판일: 2020년 6월 19일

## 소개

Denoising Diffusion Probabilistic Model(DDPM)은 기존의 Diffusion Model을 개선하여 고품질의 샘플을 생성하는 확률 모델이다. Diffusion Model은 마르코프 체인을 기반으로 한 생성 모델로, 데이터에 점진적으로 노이즈를 추가하는 **Forward Process**와 노이즈를 제거하며 데이터를 복원하는 **Reverse Process**를 포함한다. 

기존 Diffusion Model은 개념적으로 단순하고 학습이 쉬운 장점이 있지만, 생성된 샘플의 품질이 낮다는 단점이 있었다. 이에 반해 DDPM은 높은 품질의 이미지를 생성할 수 있으며, GAN 등 다른 생성 모델보다 우수한 성능을 보였다. 또한, 이 논문에서는 특정한 파라미터화(Parameterization) 방식이 Denoising Score Matching과 유사하며, 샘플링 과정이 Langevin Dynamics를 푸는 것과 동등하다는 점을 입증하였다.

DDPM의 주요 특징은 다음과 같다:
1. 높은 품질의 샘플을 생성하지만, Likelihood 기반 모델과 비교했을 때 Log Likelihood 값이 상대적으로 낮다.
2. Lossless Codelength는 주로 사람이 인지할 수 없는 이미지 세부 정보를 설명하는 데 사용된다.
3. 샘플링 과정이 Autoregressive Model의 디코딩 과정과 유사한 점진적 복원 방식으로 진행된다.

## Diffusion Model 개요

Diffusion Model은 확률적인 Forward Process와 Reverse Process를 통해 데이터를 변환하는 방식으로 동작한다. 

### 1. Forward Process (Noise 추가)
Forward Process는 데이터 \( x_0 \)에 점진적으로 가우시안 노이즈를 추가하는 과정이다. 이 과정은 다음과 같은 마르코프 체인으로 정의된다.

$$
q (x_{t}|x_{t-1}) := \mathcal{N} (x_{t} ; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)
$$

여기서, \( \beta_t \)는 노이즈의 크기를 조절하는 하이퍼파라미터로, 작은 값부터 시작하여 점진적으로 증가하는 방식으로 설정된다.

이 과정을 여러 단계 거친 후, 최종적으로 \( x_T \)는 순수한 가우시안 노이즈가 된다.

### 2. Reverse Process (Noise 제거)
Reverse Process는 가우시안 노이즈에서 점진적으로 원본 데이터를 복원하는 과정으로, 다음과 같이 정의된다.

$$
p_\theta (x_{t-1}|x_{t}) := \mathcal{N} (x_{t-1} ; \mu_\theta (x_t , t), \Sigma_\theta (x_t , t))
$$

이때, \( \mu_\theta \)는 신경망이 예측하는 평균값이며, \( \Sigma_\theta \)는 분산이다. DDPM은 이 과정을 학습된 뉴럴 네트워크를 통해 수행하며, 노이즈를 제거하는 역할을 한다.

### 3. 학습 과정
DDPM의 학습은 Variational Lower Bound를 최적화하는 방식으로 진행된다. 학습 목적 함수는 다음과 같이 표현할 수 있다.

$$
L:= \mathbb{E}_q \bigg[ -\log p_\theta (x_0) \bigg] \le \mathbb{E}_q \bigg[ -\log \frac{p_\theta (x_{0:T})}{q(x_{1:T}|x_0)} \bigg]
$$

즉, 모델은 원본 데이터를 효과적으로 복원할 수 있도록 Forward Process에서 추가된 노이즈를 제거하는 방향으로 최적화된다.

## 실험 및 결과

실험에서는 CIFAR-10, LSUN, CelebA 데이터셋을 사용하여 모델 성능을 평가하였다. 주요 실험 설정은 다음과 같다:
- **Noise Steps**: \( T = 1000 \)
- **Noise Schedule**: \( \beta_t \)를 선형적으로 증가하도록 설정
- **Neural Network**: U-Net 기반 구조, Group Normalization 사용
- **Positional Encoding**: Transformer 스타일의 시간 인코딩 적용

### 주요 성능 비교
DDPM은 기존의 생성 모델보다 FID(Frechet Inception Distance) 측면에서 우수한 성능을 보였다.

![DDPM 성능 비교](/assets/img/ddpm/ddpm-table1.webp)
![FID 점수 비교](/assets/img/ddpm/ddpm-table2.webp)

### 샘플링 결과
DDPM은 매우 높은 품질의 이미지를 생성하는 데 성공하였다.

![LSUN 샘플](/assets/img/ddpm/ddpm-lsun.webp)
![CelebA 샘플](/assets/img/ddpm/ddpm-celeba.webp)

## 결론
DDPM은 Diffusion Model의 구조를 개선하여 높은 품질의 이미지를 생성하는 데 성공한 모델이다. 주요한 특징으로는:
1. **고품질 이미지 생성**: 기존 모델보다 더 높은 FID 점수를 기록하며, 이미지 품질이 뛰어나다.
2. **단순한 학습 과정**: GAN과 달리 불안정한 학습 문제가 없으며, 상대적으로 학습이 안정적이다.
3. **Score-Based Generative Modeling과 유사한 특성**: 학습 과정이 Denoising Score Matching과 연결되며, 샘플링 과정이 Langevin Dynamics와 유사하다.

이러한 특징 덕분에 DDPM은 최근 다양한 이미지 생성 및 변형 모델의 핵심 개념으로 사용되고 있으며, Variational Diffusion Model(VDM) 및 Improved DDPM 등 다양한 후속 연구로 이어지고 있다.

