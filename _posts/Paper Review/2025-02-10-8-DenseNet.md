---
title: "[논문리뷰] Densely Connected Convolutional Networks (DenseNet)"
last_modified_at: 2025-02-10
categories:
  - 논문리뷰
  - 딥러닝
  - 컴퓨터비전

tags:
  - Computer Vision
  - AI
  - Image Classification
  - DenseNet Model

excerpt: "DenseNet 논문 리뷰"
use_math: true
classes: wide
math_engine: katex
---

> CVPR 2017. [[논문 링크](https://arxiv.org/abs/1608.06993)]  
> 저자: Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger (Cornell University, Facebook AI Research)  
> 출판일: 2017년

## 소개

DenseNet(Densely Connected Convolutional Networks)은 네트워크 내 모든 레이어가 서로 직접 연결된 CNN 모델이다. 이를 통해 정보 흐름을 최적화하고, 매개변수 수를 줄이며, 성능을 향상시킨다. DenseNet의 핵심 아이디어는 **Dense Connectivity** 구조를 통해 이전 모든 레이어의 출력을 다음 레이어로 전달하는 것이다.

![DenseNet 구조](/assets/img/densenet/densenet-architecture.webp)

### DenseNet의 주요 기여
1. **Dense Connectivity**: 각 레이어가 이전의 모든 레이어의 출력을 입력으로 받음.
2. **Gradient Flow 개선**: 깊은 네트워크에서도 Gradient Vanishing 문제가 감소.
3. **매개변수 효율성 증가**: 적은 수의 파라미터로도 높은 성능을 달성.
4. **Feature Reuse**: 중복된 특징 추출을 방지하고 더 풍부한 표현 학습 가능.

## DenseNet 구조

DenseNet의 핵심은 **Dense Block**을 활용한 네트워크 설계이다. 각 레이어는 이전 모든 레이어에서 얻어진 feature map을 입력으로 받으며, 출력 feature map을 후속 레이어에 추가한다.

### 1. Dense Block
Dense Block 내부에서는 모든 레이어가 완전히 연결되며, 이 연결은 다음과 같이 정의된다:

$$
x_l = H_l([x_0, x_1, ..., x_{l-1}])
$$

여기서 \( H_l \)은 합성곱 연산을 의미하고, \( [x_0, x_1, ..., x_{l-1}] \)는 이전 레이어들의 출력을 연결(concatenation)한 벡터이다.

![Dense Block 개념](/assets/img/densenet/dense-block.webp)

### 2. Transition Layer
각 Dense Block 사이에는 **Transition Layer**가 포함되어 feature map의 크기를 조정하고 연산량을 줄인다. 이는 **1x1 Convolution + Average Pooling**으로 구성된다.

### 3. Growth Rate (k)
각 레이어가 출력하는 feature map의 수를 **growth rate (k)**로 정의한다. 예를 들어, \( k=32 \)일 경우, 각 레이어는 32개의 새로운 feature map을 생성한다.

### 4. Bottleneck Layer
Bottleneck 구조는 네트워크의 연산량을 줄이고 효율성을 높이기 위해 사용되며, **1x1 Convolution**을 통해 feature map을 축소한 후 **3x3 Convolution**을 수행한다.

## DenseNet의 학습 방법

- **Batch Normalization 사용**: 학습 안정성을 높이고 학습 속도 향상.
- **Dropout 미사용**: Dense Connectivity 구조 덕분에 Dropout이 필요 없음.
- **SGD + Nesterov Momentum (0.9) 적용**
- **Weight Decay (1e-4) 적용**

## 실험 및 결과

DenseNet은 ImageNet, CIFAR-10, CIFAR-100, SVHN 등의 데이터셋에서 기존 CNN 모델보다 우수한 성능을 달성하였다.

| 모델  | 매개변수 수 | FLOPs | Top-1 정확도 |
|--------|------------|--------|-------------|
| ResNet-50 | 25.5M | 3.8B | 76.4% |
| DenseNet-121 | 8.0M | 2.9B | 76.9% |
| DenseNet-169 | 14.1M | 3.5B | 77.6% |

![DenseNet 성능 비교](/assets/img/densenet/densenet-performance.webp)

## 결론

DenseNet은 기존 CNN 모델의 한계를 극복하고, 적은 매개변수로도 높은 성능을 달성할 수 있는 혁신적인 네트워크이다.

1. **Dense Connectivity를 통한 Gradient Vanishing 문제 해결**
2. **매개변수 효율성을 높여 더 가벼운 모델 구현 가능**
3. **Feature Reuse를 통해 더 강력한 특징 표현 가능**

현재에도 DenseNet은 이미지 분류, 객체 검출 등 다양한 딥러닝 응용에서 널리 사용되고 있다.