---
title: "[논문리뷰] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (MobileNet)"
last_modified_at: 2025-02-10
categories:
  - 논문리뷰
  - 딥러닝
  - 컴퓨터비전

tags:
  - Computer Vision
  - AI
  - Deep Learning
  - MobileNet

excerpt: "MobileNet 논문 리뷰"
use_math: true
classes: wide
math_engine: katex
---

> CVPR 2017. [[논문 링크](https://arxiv.org/abs/1704.04861)]  
> 저자: Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam (Google Research)  
> 출판일: 2017년 4월 17일

## 소개

MobileNet은 경량화된 CNN 모델로, **모바일 및 임베디드 기기에서도 효율적으로 동작하는 신경망**을 목표로 개발되었다. Google Research에서 발표한 이 모델은 **Depthwise Separable Convolution**을 활용하여 연산량을 획기적으로 줄이면서도 높은 성능을 유지한다.

![MobileNet 구조](/assets/img/mobilenet/mobilenet-architecture.webp)

MobileNet의 주요 기여는 다음과 같다:
1. **Depthwise Separable Convolution 도입**: 연산량을 줄이면서도 높은 성능을 유지하는 핵심 기법.
2. **α-Width Multiplier**: 모델의 너비를 조절하여 계산량과 정확도를 균형 조정.
3. **ρ-Resolution Multiplier**: 입력 이미지 크기를 줄여 추가적인 연산량 감소 가능.
4. **모바일 환경에 최적화된 경량 모델**

## MobileNet 구조

MobileNet은 일반적인 CNN 모델과 달리, 연산량을 줄이기 위해 **Depthwise Separable Convolution**을 사용한다. 이는 **Depthwise Convolution과 Pointwise Convolution**으로 구성된다.

### 1. Depthwise Separable Convolution
기존 Convolution과 비교하여 계산량을 크게 줄이면서도 성능을 유지할 수 있다.

#### 기존 Convolution 연산량
기존 합성곱 연산은 다음과 같은 계산량을 가진다:

$$
D_k \times D_k \times M \times N \times D_f \times D_f
$$

여기서,
- \( D_k \) = 커널 크기
- \( M \) = 입력 채널 수
- \( N \) = 출력 채널 수
- \( D_f \) = Feature Map 크기

#### Depthwise Separable Convolution 연산량
MobileNet에서는 이를 두 단계로 나눈다:
1. **Depthwise Convolution**: 각 입력 채널별로 독립적인 필터 적용
2. **Pointwise Convolution (1×1 Conv)**: 채널 간 정보를 합치는 과정

이렇게 하면 연산량이 기존 CNN 대비 **\( 1/N + 1/ D_k^2 \)배** 감소한다.

![Depthwise Separable Convolution](/assets/img/mobilenet/depthwise-separable-convolution.webp)

### 2. Width Multiplier (α)
α 값(0~1)을 조절하여 모델의 너비를 조정할 수 있다. 작은 α 값을 사용하면 연산량이 감소하지만, 정확도가 떨어질 수 있다.

### 3. Resolution Multiplier (ρ)
입력 이미지의 해상도를 줄여서 연산량을 추가적으로 감소시킨다.

## MobileNet의 학습 방법

- **SGD with Momentum (0.9) 적용**
- **Batch Normalization 사용**
- **Dropout (0.25) 적용하여 과적합 방지**
- **ReLU6 활성화 함수 사용** (더 넓은 동작 범위를 제공)

## 실험 및 결과

MobileNet은 다양한 데이터셋에서 경량 모델로서 높은 성능을 보였다. 주요 성과는 다음과 같다:

- **ImageNet 분류**: Top-1 정확도 70.6%, Top-5 정확도 89.5%
- **YOLO 및 SSD 기반 객체 탐지에 사용 가능**
- **VGG-16 대비 8.9배 적은 연산량, 32배 적은 파라미터 수**

![MobileNet 성능 비교](/assets/img/mobilenet/mobilenet-performance.webp)

### 주요 성과
- **경량 모델로도 높은 정확도 유지**
- **모바일 및 임베디드 환경에서도 CNN 적용 가능**
- **다양한 비전 태스크(객체 탐지, 분류, 세분화)에서 활용 가능**

## 결론

MobileNet은 딥러닝 모델을 경량화하면서도 높은 정확도를 유지하는 데 성공한 모델이다. 이후 MobileNetV2, MobileNetV3 등의 후속 연구로 이어지며 더욱 발전하였다.

1. **Depthwise Separable Convolution을 통해 연산 최적화**
2. **Width 및 Resolution Multiplier를 활용한 모델 경량화**
3. **모바일 및 임베디드 환경에서도 적용 가능한 신경망 모델**

MobileNet은 현재에도 Edge AI 및 모바일 딥러닝 응용에서 널리 활용되며, 경량 모델 연구의 기반이 되고 있다.

